```js Node
import { Supadata } from "@supadata/js";

const supadata = new Supadata("YOUR_API_KEY");

// Get crawl job results
// This automatically handles pagination and returns all pages
const crawlResult = await supadata.web.getCrawlResults(jobId);

if (crawlResult.status === "completed") {
  console.log("Crawl job completed successfully!");
  console.log(`Total pages crawled: ${crawlResult.pages.length}`);
  
  // Process each page
  crawlResult.pages.forEach((page, index) => {
    console.log(`Page ${index + 1}: ${page.name}`);
    console.log(`URL: ${page.url}`);
    console.log(`Description: ${page.description}`);
    console.log(`Content preview: ${page.content.substring(0, 100)}...`);
    console.log("---");
  });
} else if (crawlResult.status === "failed") {
  console.error("Crawl job failed:", crawlResult.error);
} else {
  console.log("Job status:", crawlResult.status);
}
```